<!DOCTYPE html>
<html lang="fr">
<head>
    {% load static %}
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Journal - MindLense</title>
    <link rel="stylesheet" href="{% static 'css/home.css' %}" />
	<style>
        /* Voice Journal specific styles */
        .voice-hero {
            padding: 40px 0;
            background: linear-gradient(180deg, #ffffff, #f7fbff 55%, #f6fffb);
        }
        
        .voice-hero-content {
            text-align: center;
            max-width: 600px;
            margin: 0 auto;
        }
        
        .voice-hero h1 {
            font-size: 36px;
            line-height: 1.2;
            margin: 0 0 12px;
            color: #101828;
        }
        
        .voice-hero p {
            font-size: 18px;
            color: #475467;
            margin: 0 0 32px;
        }
        
        .recording-section {
            background: #fff;
            border: 1px solid #e5e7eb;
            border-radius: var(--radius-lg);
            padding: 32px;
            margin: 32px 0;
            box-shadow: var(--shadow-sm);
        }
        
        .record-button {
            background: var(--color-secondary);
            color: #fff;
            border: none;
            padding: 14px 28px;
            font-size: 16px;
            font-weight: 700;
            border-radius: var(--radius-md);
            cursor: pointer;
            transition: all 0.2s ease;
            margin: 8px;
            box-shadow: var(--shadow-sm);
        }
        
        .record-button:hover {
            transform: translateY(-1px);
            box-shadow: var(--shadow-md);
        }
        
        .record-button:disabled {
            background: #d1d5db;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .stop-button {
            background: var(--color-primary);
        }
        
        .audio-player {
            margin: 24px 0;
            width: 100%;
            border-radius: var(--radius-md);
        }
        
        .status {
            margin: 20px 0;
            padding: 16px;
            border-radius: var(--radius-md);
            text-align: center;
            font-weight: 600;
            border: 1px solid;
        }
        
        .status.recording {
            background: #fef2f2;
            color: #dc2626;
            border-color: #fecaca;
        }
        
        .status.processing {
            background: #eff6ff;
            color: var(--color-primary);
            border-color: #dbeafe;
        }
        
        .status.success {
            background: #f0fdf4;
            color: #16a34a;
            border-color: #bbf7d0;
        }
        
        .status.error {
            background: #fef2f2;
            color: #dc2626;
            border-color: #fecaca;
        }
        
        .results {
            margin-top: 32px;
            padding: 24px;
            background: #fff;
            border: 1px solid #e5e7eb;
            border-radius: var(--radius-lg);
            box-shadow: var(--shadow-sm);
            display: none;
        }
        
        .result-section {
            margin-bottom: 20px;
            padding: 20px;
            background: #f9fafb;
            border-radius: var(--radius-md);
            border-left: 4px solid var(--color-secondary);
        }
        
        .result-section h3 {
            margin: 0 0 12px 0;
            color: #101828;
            font-size: 18px;
            font-weight: 700;
        }
        
        .result-content {
            color: #475467;
            line-height: 1.6;
        }
        
        .sentiment-badge {
            display: inline-block;
            padding: 6px 12px;
            border-radius: 999px;
            font-size: 14px;
            font-weight: 600;
            margin: 4px 8px 4px 0;
        }
        
        .sentiment-positive {
            background: #dcfce7;
            color: #166534;
        }
        
        .sentiment-negative {
            background: #fee2e2;
            color: #991b1b;
        }
        
        .sentiment-neutral {
            background: #f3f4f6;
            color: #374151;
        }
        
        .emotion-badge {
            background: #dbeafe;
            color: #1e40af;
        }
        
        .voice-icon {
            width: 60px;
            height: 60px;
            border-radius: var(--radius-md);
            background: var(--color-secondary);
            display: grid;
            place-items: center;
            font-size: 24px;
            margin: 0 auto 16px;
            color: #fff;
        }
        
        /* Animations pour la respiration */
        @keyframes pulse {
            0% { transform: scale(1); opacity: 0.7; }
            50% { transform: scale(1.1); opacity: 1; }
            100% { transform: scale(1); opacity: 0.7; }
        }
        
        @keyframes breatheIn {
            0% { transform: scale(0.8); }
            100% { transform: scale(1.2); }
        }
        
        @keyframes breatheOut {
            0% { transform: scale(1.2); }
            100% { transform: scale(0.8); }
        }
        
        @keyframes hold {
            0% { transform: scale(1.1); }
            100% { transform: scale(1.1); }
        }
	</style>
</head>
<body>
    {% include 'partials/nav.html' %}

    <main>
        <section class="voice-hero">
            <div class="container voice-hero-content">
                <div class="voice-icon">üé§</div>
                <h1>Voice Journal</h1>
                <p>Enregistrez vos pens√©es et obtenez une analyse instantan√©e de vos √©motions</p>
            </div>
        </section>

        <section class="container">
            <div class="recording-section">
                <button id="recordButton" class="record-button">üé§ Commencer l'enregistrement</button>
                <button id="stopButton" class="record-button stop-button" disabled>‚èπÔ∏è Arr√™ter et analyser</button>
                
                <div id="status" class="status" style="display: none;"></div>
                
                <audio id="audioPlayer" class="audio-player" controls style="display: none;"></audio>
            </div>
            
            <div id="results" class="results">
                <div class="result-section">
                    <h3>üí¨ Message de l'IA</h3>
                    <div id="aiMessage" class="result-content"></div>
                </div>
                <div id="supportCard" class="result-section" style="display:none">
                    <h3>ü´∂ Soutien</h3>
                    <div id="supportText" class="result-content" style="margin-bottom:12px">Tu sembles un peu tendu(e). Veux-tu en parler?</div>
                    <div style="display:flex;gap:8px;align-items:center;flex-wrap:wrap">
                        <button id="talkToAiBtn" class="record-button">ü´∂ Commencer le soutien</button>
                        <button id="stopAiBtn" class="record-button stop-button" disabled>‚èπÔ∏è Terminer l'appel</button>
                        <span id="agentStatus" style="font-weight:600;color:#475467"></span>
                    </div>
                    <div id="agentReply" class="result-content" style="margin-top:10px"></div>
                    <div id="agentPreview" style="margin-top:10px"></div>
                    
                    <!-- Animation de respiration -->
                    <div id="breathingAnimation" style="display:none; margin-bottom:15px; text-align:center; background:#f8fafc; padding:20px; border-radius:12px; border:2px solid #e2e8f0;">
                        <div id="breathingStep" style="font-size:14px; color:#64748b; margin-bottom:8px; font-weight:500;">
                            <span id="stepText">√âtape 1/3</span>
                        </div>
                        <div id="breathingTimer" style="font-size:32px; font-weight:bold; color:#4A90E2; margin-bottom:12px;">
                            <span id="timerText">Pr√™t</span>
                        </div>
                        <div id="breathingProgress" style="width:100%; height:12px; background:#e2e8f0; border-radius:6px; overflow:hidden; margin-bottom:12px;">
                            <div id="progressBar" style="width:0%; height:100%; background:linear-gradient(90deg, #4A90E2, #50E3C2); transition:width 0.1s linear;"></div>
                        </div>
                        <div id="breathingInstruction" style="font-size:18px; color:#334155; margin-bottom:12px; font-weight:600;">
                            <span id="instructionText">En attente...</span>
                        </div>
                        <div id="breathingVisual" style="width:80px; height:80px; margin:0 auto; border-radius:50%; background:#4A90E2; opacity:0.8; transition:all 0.3s ease; box-shadow:0 4px 12px rgba(74, 144, 226, 0.3);"></div>
                    </div>
                </div>
                <div class="result-section">
                    <h3>üìù Transcription</h3>
                    <div id="transcription" class="result-content"></div>
		</div>

                <div class="result-section">
                    <h3>üòä Sentiment du texte</h3>
                    <div id="textSentiment" class="result-content"></div>
                </div>
                
                <div class="result-section" id="audioEmotionSection" style="display:none">
                    <h3>üéµ √âmotion audio</h3>
                    <div id="audioEmotion" class="result-content"></div>
                </div>

                <div class="result-section">
                    <h3>üé∂ Recommandations musicales</h3>
                    <div id="musicList" class="result-content" style="display:grid;gap:12px"></div>
		</div>
	</div>
        </section>
    </main>

    {% include 'partials/footer.html' %}

	<script>
        class VoiceJournal {
            constructor() {
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.chunkCount = 0;
                
                this.recordButton = document.getElementById('recordButton');
                this.stopButton = document.getElementById('stopButton');
                this.status = document.getElementById('status');
                this.audioPlayer = document.getElementById('audioPlayer');
                this.results = document.getElementById('results');
                
                this.setupEventListeners();
                console.log('[VoiceJournal] Initialized');
            }
            
            setupEventListeners() {
                this.recordButton.addEventListener('click', () => this.startRecording());
                this.stopButton.addEventListener('click', () => this.stopRecording());
                console.log('[VoiceJournal] Event listeners attached');
            }
            
            async startRecording() {
                try {
                    console.log('[VoiceJournal] Requesting microphone permission...');
				const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    console.log('[VoiceJournal] Microphone stream obtained');
                    
                    this.mediaRecorder = new MediaRecorder(stream);
                    this.audioChunks = [];
                    this.chunkCount = 0;
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        this.audioChunks.push(event.data);
                        this.chunkCount += 1;
                        console.log(`[VoiceJournal] ondataavailable: chunk ${this.chunkCount}, size=${event.data?.size}`);
                    };
                    
                    this.mediaRecorder.onstop = () => {
                        console.log(`[VoiceJournal] Recorder stopped. Total chunks: ${this.chunkCount}`);
                        this.processRecording();
                    };
                    
                    this.mediaRecorder.start();
                    console.log('[VoiceJournal] Recording started');
                    this.isRecording = true;
                    
                    this.updateUI('recording', 'üî¥ Enregistrement en cours... Cliquez sur "Arr√™ter et analyser" quand vous avez termin√©');
                    this.recordButton.disabled = true;
                    this.stopButton.disabled = false;
                    
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.updateUI('error', '‚ùå Erreur d\'acc√®s au microphone. Veuillez v√©rifier les permissions.');
                }
            }
            
            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    console.log('[VoiceJournal] Stopping recording...');
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    
                    this.updateUI('processing', '‚è≥ Traitement de votre audio...');
                    this.stopButton.disabled = true;
                }
            }
            
            async processRecording() {
                try {
                    console.log(`[VoiceJournal] Processing recording. Chunks: ${this.audioChunks.length}`);
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    console.log(`[VoiceJournal] Blob created. Size=${audioBlob.size} type=${audioBlob.type}`);
                    
                    // Show the recorded audio
                    const audioUrl = URL.createObjectURL(audioBlob);
                    this.audioPlayer.src = audioUrl;
                    this.audioPlayer.style.display = 'block';
                    console.log('[VoiceJournal] Audio preview ready');
                    
                    // Send to server for processing
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');
                    console.log('[VoiceJournal] Sending fetch -> /voice-journal/process-audio/');
                    const t0 = performance.now();
                    
                    const response = await fetch('/voice-journal/process-audio/', {
                        method: 'POST',
                        body: formData,
                        headers: {
                            'X-CSRFToken': this.getCSRFToken()
                        }
                    });
                    const t1 = performance.now();
                    console.log(`[VoiceJournal] Fetch completed. status=${response.status} (${(t1 - t0).toFixed(0)} ms)`);
                    let result = null;
                    try {
                        result = await response.json();
                    } catch (e) {
                        console.warn('[VoiceJournal] Failed to parse JSON response', e);
                    }
                    console.log('[VoiceJournal] Server response:', result);
                    if (result && typeof result.transcription === 'string') {
                        console.log('[VoiceJournal] Transcription (main):', result.transcription);
                    }
                    
                    if (result.success) {
                        this.displayResults(result);
                        this.updateUI('success', '‚úÖ Analyse termin√©e avec succ√®s !');
                    } else {
                        const missing = Array.isArray(result?.missing) ? `\nManquant: ${result.missing.join(', ')}` : '';
                        this.updateUI('error', `‚ùå Erreur: ${result?.error || 'Erreur inconnue'}` + missing);
                        console.error('[VoiceJournal] Error result:', result);
                    }
                    
                } catch (error) {
                    console.error('Error processing audio:', error);
                    this.updateUI('error', '‚ùå Erreur lors du traitement audio. Veuillez r√©essayer.');
                } finally {
                    this.recordButton.disabled = false;
                    this.stopButton.disabled = true;
                }
            }
            
            displayResults(result) {
                // Show success immediately before any secondary fetches (music)
                try { this.updateUI('success', '‚úÖ Analyse termin√©e !'); } catch {}
                document.getElementById('transcription').textContent = result.transcription;
                
                const sentimentClass = result.text_sentiment.toLowerCase();
                document.getElementById('textSentiment').innerHTML = `
                    <span class="sentiment-badge sentiment-${sentimentClass}">
                        ${result.text_sentiment} (${result.text_sentiment_score.toFixed(2)})
                    </span>
                `;
                
                // Hide audio emotion; we rely on text sentiment for UX
                try { document.getElementById('audioEmotionSection').style.display = 'none'; } catch {}

                // AI message
                const aiMsgEl = document.getElementById('aiMessage');
                aiMsgEl.textContent = result.ai_message || '';

                // Suggestion card for sad/stressed
                const supportCard = document.getElementById('supportCard');
                const supportText = document.getElementById('supportText');
                const mood = (result.emotion || '').toLowerCase();
                if (mood === 'sad' || mood === 'stressed') {
                    supportText.textContent = mood === 'sad'
                        ? "Tu sembles un peu triste. Veux-tu en parler √† voix haute? Clique sur 'Commencer le soutien' pour d√©marrer une conversation avec l'assistant."
                        : "Tu sembles stress√©(e). Souhaites-tu une courte discussion guid√©e? Clique sur 'Commencer le soutien' pour d√©marrer une conversation avec l'assistant.";
                    supportCard.style.display = 'block';
                    supportCard.dataset.mood = mood;
                    // Ne pas d√©marrer automatiquement - attendre que l'utilisateur clique sur le bouton
                } else {
                    supportCard.style.display = 'none';
                }

                // Dynamic theme (apply to hero background)
                if (result.theme && result.theme.primary && result.theme.secondary) {
                    const hero = document.querySelector('.voice-hero');
                    hero.style.background = `linear-gradient(180deg, ${result.theme.primary}, ${result.theme.secondary})`;
                }

                // Music cards (render spinner first, then fetch async if needed)
                const musicList = document.getElementById('musicList');
                const renderCard = (item) => {
                    const card = document.createElement('div');
                    card.style.display = 'grid';
                    card.style.gridTemplateColumns = '160px 1fr';
                    card.style.gap = '12px';
                    card.style.alignItems = 'center';
                    card.style.padding = '10px';
                    card.style.border = '1px solid #e5e7eb';
                    card.style.borderRadius = '12px';

                    // If Jamendo audioUrl present, render audio player; else fallback to thumbnail link (avoid iframes that 503/X-Frame-Options)
                    if (item.audioUrl) {
                        const audio = document.createElement('audio');
                        audio.src = item.audioUrl;
                        audio.controls = true;
                        audio.preload = 'metadata';
                        audio.style.width = '160px';
                        card.appendChild(audio);
                    }

                    // Lite inline embed: clickable thumbnail swaps to in-page youtube-nocookie iframe (no navigation)
                    const vidId = item.videoId || (item.embedUrl ? (item.embedUrl.split('/embed/')[1] || '').split('?')[0] : '');
                    const thumbSrc = item.thumbnail || (vidId ? `https://i.ytimg.com/vi/${vidId}/hqdefault.jpg` : '');
                    if (vidId) {
                        const container = document.createElement('div');
                        container.style.position = 'relative';
                        container.style.width = '160px';
                        container.style.height = '90px';
                        container.style.borderRadius = '8px';
                        container.style.overflow = 'hidden';

                        const img = document.createElement('img');
                        img.src = thumbSrc;
                        img.width = 160;
                        img.height = 90;
                        img.style.display = 'block';
                        img.style.width = '160px';
                        img.style.height = '90px';
                        img.style.objectFit = 'cover';
                        img.alt = item.title || 'Cliquez pour √©couter';

                        const overlay = document.createElement('div');
                        overlay.style.position = 'absolute';
                        overlay.style.top = '0';
                        overlay.style.left = '0';
                        overlay.style.right = '0';
                        overlay.style.bottom = '0';
                        overlay.style.display = 'flex';
                        overlay.style.alignItems = 'center';
                        overlay.style.justifyContent = 'center';
                        overlay.style.background = 'rgba(0,0,0,0.15)';

                        const playBtn = document.createElement('div');
                        playBtn.style.width = '48px';
                        playBtn.style.height = '36px';
                        playBtn.style.background = 'rgba(23, 35, 34, 0.9)';
                        playBtn.style.borderRadius = '10px';
                        playBtn.style.display = 'flex';
                        playBtn.style.alignItems = 'center';
                        playBtn.style.justifyContent = 'center';
                        playBtn.innerHTML = '<svg width="18" height="18" viewBox="0 0 24 24" fill="white"><path d="M8 5v14l11-7z"/></svg>';

                        overlay.appendChild(playBtn);
                        container.appendChild(img);
                        container.appendChild(overlay);

                        // On click, swap to iframe (in-page playback)
                        container.addEventListener('click', () => {
                            const iframe = document.createElement('iframe');
                            iframe.width = '160';
                            iframe.height = '90';
                            iframe.frameBorder = '0';
                            iframe.allow = 'accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share';
                            iframe.allowFullscreen = true;
                            iframe.referrerPolicy = 'no-referrer-when-downgrade';
                            const params = 'autoplay=1&controls=1&playsinline=1&modestbranding=1&rel=0';
                            iframe.src = `https://www.youtube-nocookie.com/embed/${vidId}?${params}`;
                            container.replaceWith(iframe);
                        }, { once: true });

                        img.onerror = function () {
                            const candidates = [
                                `https://img.youtube.com/vi/${vidId}/hqdefault.jpg`,
                                `https://i.ytimg.com/vi/${vidId}/sddefault.jpg`,
                                `https://img.youtube.com/vi/${vidId}/mqdefault.jpg`,
                                `https://img.youtube.com/vi/${vidId}/maxresdefault.jpg`,
                                `https://img.youtube.com/vi/${vidId}/default.jpg`
                            ];
                            const tried = img.dataset.tried ? img.dataset.tried.split('|') : [];
                            const next = candidates.find(u => !tried.includes(u));
                            if (next) {
                                tried.push(next);
                                img.dataset.tried = tried.join('|');
                                img.src = next;
                            }
                        };

                        card.appendChild(container);
                    } else {
                        const ph = document.createElement('div');
                        ph.style.width = '160px';
                        ph.style.height = '90px';
                        ph.style.borderRadius = '8px';
                        ph.style.background = '#f3f4f6';
                        ph.style.display = 'grid';
                        ph.style.placeItems = 'center';
                        ph.textContent = 'Preview indisponible';
                        card.appendChild(ph);
                    }

                    const meta = document.createElement('div');
                    meta.style.fontWeight = '700';
                    meta.style.fontSize = '14px';
                    meta.textContent = item.title || 'Recommended music';
                    card.appendChild(meta);

                    musicList.appendChild(card);
                };

                musicList.innerHTML = '';
                const initial = Array.isArray(result.music) ? result.music : [];
                if (initial.length) {
                    initial.forEach(renderCard);
                } else {
                    // show spinner and fetch asynchronously
                    const spinner = document.createElement('div');
                    spinner.textContent = 'Chargement des recommandations‚Ä¶';
                    spinner.style.color = '#64748b';
                    spinner.style.fontStyle = 'italic';
                    musicList.appendChild(spinner);
                    const startFetch = () => {
                        try {
                            fetch('/voice-journal/api/music/', {
                                method: 'POST',
                                body: new URLSearchParams({ mood: result.emotion || 'neutral' }),
                                headers: { 'X-CSRFToken': (document.querySelector('[name=csrfmiddlewaretoken]')?.value || '') }
                            }).then(r => r.json()).then(data => {
                                musicList.innerHTML = '';
                                (data.music || []).forEach(renderCard);
                            }).catch(() => { spinner.textContent = 'Aucune recommandation trouv√©e.'; });
                        } catch { spinner.textContent = 'Aucune recommandation trouv√©e.'; }
                    };
                    // Defer network call to let the UI paint the success state first
                    if (window.requestAnimationFrame) requestAnimationFrame(() => setTimeout(startFetch, 0)); else setTimeout(startFetch, 0);
                }
                
                this.results.style.display = 'block';
                
                // Scroll to results
                this.results.scrollIntoView({ behavior: 'smooth' });
            }
            
            updateUI(type, message) {
                this.status.textContent = message;
                this.status.className = `status ${type}`;
                this.status.style.display = 'block';
            }
            
            getCSRFToken() {
                return document.querySelector('[name=csrfmiddlewaretoken]')?.value || 
                       document.cookie.match(/csrftoken=([^;]+)/)?.[1] || '';
            }
        }
        
        // Initialize the voice journal when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceJournal();
            setupVoiceAgent();
		});

        // --- Voice Agent JS ---
        function setupVoiceAgent() {
            const talkBtn = document.getElementById('talkToAiBtn');
            const stopBtn = document.getElementById('stopAiBtn');
            const statusEl = document.getElementById('agentStatus');
            const replyEl = document.getElementById('agentReply');
            const supportCard = document.getElementById('supportCard');
            let agentRecorder = null;
            let agentChunks = [];
            let agentStream = null;
            let audioCtx = null;
            let analyser = null;
            let rafId = null;
            let inCall = false;
            let listeningActive = false;

            window.voiceAgentAutoStart = async function() {
                if (inCall) return;
                await startConversation();
            }

            async function startConversation() {
                inCall = true;
                replyEl.textContent = '';
                statusEl.textContent = 'Connexion‚Ä¶';
                talkBtn.disabled = true;
                stopBtn.disabled = false;
                try {
                    const fd = new FormData();
                    const mood = supportCard?.dataset?.mood || '';
                    if (mood) fd.append('mood', mood);
                    fd.append('start', '1');
                    const res = await fetch('/voice-journal/api/voice-agent-turn/', {
                        method: 'POST',
                        body: fd,
                        headers: { 'X-CSRFToken': (document.querySelector('[name=csrfmiddlewaretoken]')?.value || '') }
                    });
                    const data = await res.json();
                    if (data && typeof data.user_text === 'string') {
                        console.log('[VoiceAgent] Transcription (turn):', data.user_text);
                    }
                    if (!data.success) throw new Error(data.error || 'start failed');
                    replyEl.textContent = data.reply_text || '';
                    statusEl.textContent = 'Assistant parle‚Ä¶';
                    speakText(replyEl.textContent, (data.mood || ''), () => beginListening());
                } catch (e) {
                    statusEl.textContent = 'Erreur d√©marrage';
                    inCall = false;
                    talkBtn.disabled = false;
                    stopBtn.disabled = true;
                }
            }

            async function beginListening() {
                if (!inCall) return;
                if (listeningActive) return;
                statusEl.textContent = '√âcoute‚Ä¶ (parlez, prenez votre temps)';
                agentChunks = [];
                listeningActive = true;
                try {
                    agentStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioCtx.createMediaStreamSource(agentStream);
                    analyser = audioCtx.createAnalyser();
                    analyser.fftSize = 2048;
                    source.connect(analyser);
                    const dataArray = new Uint8Array(analyser.fftSize);
                    let mime = 'audio/webm;codecs=opus';
                    if (!MediaRecorder.isTypeSupported(mime)) mime = 'audio/webm';
                    if (!MediaRecorder.isTypeSupported(mime)) mime = '';
                    agentRecorder = new MediaRecorder(agentStream, mime ? { mimeType: mime } : undefined);
                    agentRecorder.ondataavailable = (e) => { if (e && e.data && e.data.size) agentChunks.push(e.data); };
                    // Use a timeslice so dataavailable fires periodically even for short utterances
                    agentRecorder.start(300);

                    let silentMs = 0;
                    const threshold = 10; // L√©g√®rement moins sensible au faux silence
                    const minSpeechMs = 1200; // Attendre plus longtemps avant d'autoriser la d√©tection de fin
                    let totalMs = 0;
                    const intervalMs = 100;
                    const tick = async () => {
                        if (!inCall) return;
                        analyser.getByteTimeDomainData(dataArray);
                        let sum = 0;
                        for (let i = 0; i < dataArray.length; i++) {
                            const v = dataArray[i] - 128;
                            sum += Math.abs(v);
                        }
                        const avg = sum / dataArray.length;
                        totalMs += intervalMs;
                        if (avg < threshold && totalMs > minSpeechMs) {
                            silentMs += intervalMs;
                        } else {
                            silentMs = 0;
                        }
                        
                        // D√©tecter si on attend une r√©ponse musicale simple (oui/non)
                        const currentReply = replyEl.textContent.toLowerCase();
                        const isMusicResponse = currentReply.includes('aimes') || 
                                               currentReply.includes('extrait') || 
                                               currentReply.includes('musique') ||
                                               currentReply.includes('oui/non') ||
                                               currentReply.includes('ou pas');
                        
                        // R√©duire le d√©lai de silence pour r√©pondre plus vite
                        const isQuickResponse = isMusicResponse || 
                                               currentReply.includes('dis-moi') ||
                                               currentReply.includes('veux-tu') ||
                                               currentReply.includes('souhaites-tu') ||
                                               currentReply.includes('besoin d\'autre chose');
                        
                        const silenceThreshold = isQuickResponse ? 1400 : 2600; // 1.4s pour r√©ponses rapides, 2.6s sinon
                        
                        if (silentMs >= silenceThreshold) {
                            // D√©lai suppl√©mentaire pour s'assurer que l'utilisateur a termin√©
                            statusEl.textContent = 'Traitement‚Ä¶ (attendez)';

                            const delay = isQuickResponse ? 250 : 500; // L√©g√®re marge avant de couper
                            setTimeout(async () => {
                                await finalizeTurn();
                            }, delay);
                            return;
                        }
                        rafId = setTimeout(tick, intervalMs);
                    };
                    rafId = setTimeout(tick, intervalMs);
                } catch (e) {
                    statusEl.textContent = 'Erreur micro';
                    endCallCleanup();
                }
            }

            async function finalizeTurn() {
                try { if (rafId) { clearTimeout(rafId); rafId = null; } } catch {}
                // Stop the recorder and WAIT for its onstop to flush last chunk
                try {
                    if (agentRecorder && agentRecorder.state !== 'inactive') {
                        const stopped = new Promise(resolve => {
                            const prevOnStop = agentRecorder.onstop;
                            agentRecorder.onstop = (...args) => { try { prevOnStop && prevOnStop(...args); } catch {} resolve(); };
                        });
                        agentRecorder.stop();
                        await stopped;
                    }
                } catch {}
                try { if (agentStream) agentStream.getTracks().forEach(t => t.stop()); } catch {}
                try { if (audioCtx && audioCtx.state !== 'closed') audioCtx.close(); } catch {}
                listeningActive = false;
                statusEl.textContent = 'Analyse‚Ä¶';

                try {
                    const size = agentChunks.reduce((s, b) => s + (b?.size || 0), 0);
                    console.log('[VoiceAgent] Turn size (bytes):', size);
                    if (!size) {
                        // Pendant les exercices de respiration, ne pas consid√©rer le silence comme une erreur
                        const supportCard = document.getElementById('supportCard');
                        const currentReply = replyEl.textContent.toLowerCase();
                        const isBreathingExercise = currentReply.includes('respir') || 
                                                   currentReply.includes('inspire') || 
                                                   currentReply.includes('bloque') || 
                                                   currentReply.includes('expire');
                        
                        if (isBreathingExercise) {
                            statusEl.textContent = "Continuez l'exercice...";
                            // Envoyer une requ√™te vide pour continuer l'exercice
                            const fd = new FormData();
                            fd.append('audio', new Blob(), 'empty.webm');
                            const mood = supportCard?.dataset?.mood || '';
                            if (mood) fd.append('mood', mood);
                            
                            try {
                                const res = await fetch('/voice-journal/api/voice-agent-turn/', {
                                    method: 'POST',
                                    body: fd,
                                    headers: { 'X-CSRFToken': (document.querySelector('[name=csrfmiddlewaretoken]')?.value || '') }
                                });
                                const data = await res.json();
                                if (data.success) {
                                    replyEl.textContent = data.reply_text || '';
                                    statusEl.textContent = 'Assistant parle‚Ä¶';
                                    speakText(replyEl.textContent, (data.mood || ''), () => {
                                        if (data.end_call) {
                                            stopCall();
                                        } else {
                                            beginListening();
                                        }
                                    });
                                    return;
                                }
                            } catch (e) {
                                console.log('Erreur lors de la continuation de l\'exercice:', e);
                            }
                        }
                        
                        statusEl.textContent = "Je n'ai rien capt√©. R√©essayons.";
                        if (inCall) setTimeout(() => beginListening(), 400);
                        return;
                    }
                    const blob = new Blob(agentChunks, { type: 'audio/webm' });
                    const fd = new FormData();
                    fd.append('audio', blob, 'agent_turn.webm');
                    const mood = supportCard?.dataset?.mood || '';
                    if (mood) fd.append('mood', mood);
                    const res = await fetch('/voice-journal/api/voice-agent-turn/', {
                        method: 'POST',
                        body: fd,
                        headers: { 'X-CSRFToken': (document.querySelector('[name=csrfmiddlewaretoken]')?.value || '') }
                    });
                    const data = await res.json();
                    if (!data.success) throw new Error(data.error || 'turn failed');
                    if (typeof data.intent === 'string') {
                        console.log('[VoiceAgent] Detected intent:', data.intent);
                    }
                    replyEl.textContent = data.reply_text || '';
                    // Render optional music preview and manage flow
                    const pv = document.getElementById('agentPreview');
                    const hadPreview = !!pv.dataset.currentEmbed;
                    if (data.preview && (data.preview.embedUrl || data.preview.audioUrl)) {
                        // Keep preview visible and reusable; only replace if new
                        const currentKey = data.preview.audioUrl || data.preview.embedUrl;
                        if (pv.dataset.currentEmbed !== currentKey) {
                            pv.innerHTML = '';
                            // Try audio first if present; else prepare youtube data
                            const previewUrl = data.preview.embedUrl || '';
                            const vidId = previewUrl ? (previewUrl.split('/embed/')[1] || '').split('?')[0] : '';
                            const thumbSrc = vidId ? `https://i.ytimg.com/vi/${vidId}/hqdefault.jpg` : '';
                            const watchUrl = vidId ? `https://www.youtube.com/watch?v=${vidId}` : previewUrl;

                            if (vidId) {
                                // Same UX as recommendations: click-to-play thumbnail swaps to in-page embed, then 15s timer
                                const container = document.createElement('div');
                                container.style.position = 'relative';
                                container.style.width = '280px';
                                container.style.height = '158px';
                                container.style.borderRadius = '8px';
                                container.style.overflow = 'hidden';

                                const img = document.createElement('img');
                                img.src = thumbSrc;
                                img.width = 280;
                                img.height = 158;
                                img.style.display = 'block';
                                img.style.width = '280px';
                                img.style.height = '158px';
                                img.style.objectFit = 'cover';
                                img.alt = data.preview.title || 'Cliquez pour √©couter';

                                const overlay = document.createElement('div');
                                overlay.style.position = 'absolute';
                                overlay.style.top = '0';
                                overlay.style.left = '0';
                                overlay.style.right = '0';
                                overlay.style.bottom = '0';
                                overlay.style.display = 'flex';
                                overlay.style.alignItems = 'center';
                                overlay.style.justifyContent = 'center';
                                overlay.style.background = 'rgba(0,0,0,0.15)';

                                const playBtn = document.createElement('div');
                                playBtn.style.width = '68px';
                                playBtn.style.height = '48px';
                                playBtn.style.background = 'rgba(23, 35, 34, 0.9)';
                                playBtn.style.borderRadius = '14px';
                                playBtn.style.display = 'flex';
                                playBtn.style.alignItems = 'center';
                                playBtn.style.justifyContent = 'center';
                                playBtn.innerHTML = '<svg width="24" height="24" viewBox="0 0 24 24" fill="white"><path d="M8 5v14l11-7z"/></svg>';

                                overlay.appendChild(playBtn);
                                container.appendChild(img);
                                container.appendChild(overlay);
                                // Autoplay inline without click (muted for autoplay policies)
                                const iframe = document.createElement('iframe');
                                iframe.width = '280';
                                iframe.height = '158';
                                iframe.frameBorder = '0';
                                iframe.allow = 'accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share';
                                iframe.allowFullscreen = true;
                                iframe.referrerPolicy = 'no-referrer-when-downgrade';
                                let src = previewUrl && previewUrl.includes('youtube') ? previewUrl : `https://www.youtube-nocookie.com/embed/${vidId}`;
                                const joiner = src.includes('?') ? '&' : '?';
                                if (!/([?&])start=/.test(src)) src += `${joiner}start=0`;
                                if (!/([?&])end=/.test(src)) src += `${src.includes('?') ? '&' : '?'}end=15`;
                                if (!/([?&])autoplay=/.test(src)) src += `${src.includes('?') ? '&' : '?'}autoplay=1`;
                                if (!/([?&])playsinline=/.test(src)) src += `${src.includes('?') ? '&' : '?'}playsinline=1`;
                                if (!/([?&])controls=/.test(src)) src += `${src.includes('?') ? '&' : '?'}controls=1`;
                                if (!/([?&])enablejsapi=/.test(src)) src += `${src.includes('?') ? '&' : '?'}enablejsapi=1`;
                                if (!/([?&])origin=/.test(src)) src += `${src.includes('?') ? '&' : '?'}origin=${encodeURIComponent(location.origin)}`;
                                iframe.src = src.replace('https://www.youtube.com/embed/', 'https://www.youtube-nocookie.com/embed/');
                                pv.appendChild(iframe);
                                statusEl.textContent = 'Extrait en cours‚Ä¶';
                                // Try to unmute and set volume once player is ready
                                try {
                                    const unmute = () => {
                                        try {
                                            iframe.contentWindow && iframe.contentWindow.postMessage(JSON.stringify({
                                                event: 'command',
                                                func: 'unMute',
                                                args: []
                                            }), '*');
                                            iframe.contentWindow && iframe.contentWindow.postMessage(JSON.stringify({
                                                event: 'command',
                                                func: 'setVolume',
                                                args: [100]
                                            }), '*');
                                        } catch {}
                                    };
                                    iframe.addEventListener('load', () => setTimeout(unmute, 300));
                                    setTimeout(unmute, 1200);
                                } catch {}
                                setTimeout(() => {
                                    if (!inCall) return;
                                    statusEl.textContent = 'Assistant parle‚Ä¶';
                                    speakText('Tu aimes ou pas ?', '', () => { if (inCall) beginListening(); });
                                }, 15500);
                            }

                            pv.dataset.currentEmbed = currentKey;
                        }
                        if (data.end_call) {
                            stopCall();
                        }
                    } else {
                        // No preview; proceed with TTS + normal loop
                        // Do not clear pv here so the user can still click the previous video
                        statusEl.textContent = 'Assistant parle‚Ä¶';
                        speakText(replyEl.textContent, (data.mood || ''), () => {
                            if (data.end_call) {
                                stopCall();
                            } else {
                                beginListening();
                            }
                        });
                    }
                } catch (e) {
                    statusEl.textContent = 'Erreur agent';
                    // keep call but allow retry listening
                    if (inCall) setTimeout(() => beginListening(), 600);
                }
            }

            function speakText(text, mood, onend) {
                try {
                    const utter = new SpeechSynthesisUtterance(text);
                    utter.lang = 'fr-FR';
                    utter.rate = 1.0;
                    if (mood === 'sad') utter.rate = 0.95;
                    if (mood === 'stressed') utter.rate = 0.98;
                    window.speechSynthesis.cancel();
                    
                    // D√©tecter les instructions de respiration AVANT de parler
                    let breathingAnimationType = null;
                    let breathingDuration = 0;
                    if (text && typeof text === 'string') {
                        const breathingText = text.toLowerCase();
                        
                        // Masquer l'animation si l'exercice est termin√©
                        if (breathingText.includes('tr√®s bien') || 
                            breathingText.includes('refait') || 
                            breathingText.includes('besoin d\'autre chose') ||
                            breathingText.includes('souhaites-tu refaire')) {
                            setTimeout(() => {
                                const animationEl = document.getElementById('breathingAnimation');
                                animationEl.style.display = 'none';
                                breathingStepCount = 0;
                            }, 1000);
                        }
                        // D√©tecter "Inspire 4 secondes"
                        else if (breathingText.includes('inspire 4')) {
                            breathingAnimationType = 'inspire';
                            breathingDuration = 4;
                        }
                        // D√©tecter "Bloque 4 secondes"
                        else if (breathingText.includes('bloque 4')) {
                            breathingAnimationType = 'hold';
                            breathingDuration = 4;
                        }
                        // D√©tecter "Expire 6 secondes"
                        else if (breathingText.includes('expire') && breathingText.includes('6')) {
                            breathingAnimationType = 'expire';
                            breathingDuration = 6;
                        }
                    }
                    
                    // Cr√©er le callback qui g√®re √† la fois onend et l'animation
                    utter.onend = () => { 
                        if (typeof onend === 'function') onend();
                        // D√©clencher l'animation apr√®s que l'AI termine de parler
                        if (breathingAnimationType) {
                            triggerBreathingStep(breathingAnimationType, breathingDuration);
                        }
                    };
                    
                    window.speechSynthesis.speak(utter);
                } catch {}
            }
            
            // Animation de respiration avec gestion des √©tapes
            let breathingStepCount = 0;
            let breathingInterval = null;
            
            function triggerBreathingStep(type, duration) {
                const animationEl = document.getElementById('breathingAnimation');
                const stepEl = document.getElementById('stepText');
                const timerEl = document.getElementById('timerText');
                const progressEl = document.getElementById('progressBar');
                const instructionEl = document.getElementById('instructionText');
                const visualEl = document.getElementById('breathingVisual');
                
                // Afficher l'animation si ce n'est pas d√©j√† fait
                animationEl.style.display = 'block';
                
                // Arr√™ter toute animation en cours
                if (breathingInterval) {
                    clearInterval(breathingInterval);
                    breathingInterval = null;
                }
                
                // D√©finir le texte et le style selon le type
                let text, style, stepNum;
                if (type === 'inspire') {
                    text = 'Inspirez pendant 4 secondes';
                    style = 'inspire';
                    stepNum = 1;
                    breathingStepCount = 1;  // Premi√®re vraie √©tape
                } else if (type === 'hold') {
                    text = 'Bloquez pendant 4 secondes';
                    style = 'hold';
                    stepNum = 2;
                    breathingStepCount = 2;  // Deuxi√®me √©tape
                } else if (type === 'expire') {
                    text = 'Expirez pendant 6 secondes';
                    style = 'expire';
                    stepNum = 3;
                    breathingStepCount = 3;  // Troisi√®me √©tape
                }
                
                // Mettre √† jour l'interface
                stepEl.textContent = `√âtape ${stepNum}/3`;
                instructionEl.textContent = text;
                timerEl.textContent = duration;
                progressEl.style.width = '0%';
                
                // Animation visuelle selon le type
                updateVisualStyle(visualEl, style);
                
                let timeLeft = duration;
                
                breathingInterval = setInterval(() => {
                    timeLeft--;
                    timerEl.textContent = timeLeft;
                    
                    // Mettre √† jour la barre de progression
                    const progress = ((duration - timeLeft) / duration) * 100;
                    progressEl.style.width = progress + '%';
                    
                    // Animation du cercle
                    const scale = 0.8 + (progress / 100) * 0.4;
                    visualEl.style.transform = `scale(${scale})`;
                    
                    if (timeLeft <= 0) {
                        clearInterval(breathingInterval);
                        timerEl.textContent = '‚úì';
                        progressEl.style.width = '100%';
                        visualEl.style.transform = 'scale(1)';
                        breathingInterval = null;
                        
                        // Si ce n'est pas la derni√®re √©tape, r√©cup√©rer automatiquement l'√©tape suivante
                        if (breathingStepCount < 3 && inCall) {
                            // Petit d√©lai pour que l'utilisateur voie le ‚úì
                        setTimeout(() => {
                                requestNextBreathingStep();
                            }, 300);
                        }
                    }
                }, 1000);
            }
            
            async function requestNextBreathingStep() {
                // Envoyer une requ√™te vide au serveur pour obtenir l'√©tape suivante
                try {
                    const fd = new FormData();
                    fd.append('audio', new Blob(), 'empty.webm');
                    const supportCard = document.getElementById('supportCard');
                    const mood = supportCard?.dataset?.mood || '';
                    if (mood) fd.append('mood', mood);
                    
                    const res = await fetch('/voice-journal/api/voice-agent-turn/', {
                        method: 'POST',
                        body: fd,
                        headers: { 'X-CSRFToken': (document.querySelector('[name=csrfmiddlewaretoken]')?.value || '') }
                    });
                    const data = await res.json();
                    if (data.success) {
                        const replyEl = document.getElementById('agentReply');
                        replyEl.textContent = data.reply_text || '';
                        statusEl.textContent = 'Assistant parle‚Ä¶';
                        
                        const replyText = replyEl.textContent.toLowerCase();
                        
                        // Si le texte contient "Tr√®s bien" ou "refait", on a termin√© l'exercice
                        if (replyText.includes('tr√®s bien') || replyText.includes('refait') || replyText.includes('besoin d\'autre chose')) {
                            // Attendre que l'utilisateur r√©ponde avant de commencer √† √©couter
                            speakText(replyEl.textContent, (data.mood || ''), () => {
                                if (data.end_call) {
                                    stopCall();
                                } else {
                                    // Laisser un petit d√©lai puis commencer √† √©couter
                                    setTimeout(() => {
                                        if (inCall) beginListening();
                                    }, 500);
                                }
                            });
                        } 
                        // Si c'est l'introduction "commence une respiration", obtenir la prochaine √©tape imm√©diatement
                        else if (replyText.includes('commence une respiration')) {
                            speakText(replyEl.textContent, (data.mood || ''), () => {
                                // Attendre un instant puis obtenir l'√©tape suivante (Inspire 4 secondes)
                                setTimeout(() => {
                                    requestNextBreathingStep();
                                }, 300);
                            });
                        }
                        // C'est une instruction de respiration, d√©marrer l'animation apr√®s que l'AI parle
                        else {
                            speakText(replyEl.textContent, (data.mood || ''), () => {
                                if (data.end_call) {
                                    stopCall();
                                }
                                // Ne pas appeler beginListening - l'animation sera d√©clench√©e automatiquement
                            });
                        }
                    }
                } catch (e) {
                    console.log('Erreur lors de la r√©cup√©ration de l\'√©tape suivante:', e);
                }
            }
            
            function updateVisualStyle(element, style) {
                element.className = '';
                switch(style) {
                    case 'inspire':
                        element.style.background = 'linear-gradient(45deg, #4A90E2, #50E3C2)';
                        element.style.animation = 'pulse 1s infinite';
                        break;
                    case 'hold':
                        element.style.background = '#F5A623';
                        element.style.animation = 'none';
                        break;
                    case 'expire':
                        element.style.background = 'linear-gradient(45deg, #50E3C2, #4A90E2)';
                        element.style.animation = 'pulse 1.5s infinite';
                        break;
                    default:
                        element.style.background = '#4A90E2';
                        element.style.animation = 'none';
                }
            }

            function endCallCleanup() {
                try { window.speechSynthesis.cancel(); } catch {}
                try { if (rafId) { clearTimeout(rafId); rafId = null; } } catch {}
                try { if (agentRecorder && agentRecorder.state !== 'inactive') agentRecorder.stop(); } catch {}
                try { if (agentStream) agentStream.getTracks().forEach(t => t.stop()); } catch {}
                try { if (audioCtx && audioCtx.state !== 'closed') audioCtx.close(); } catch {}
                try { if (breathingInterval) { clearInterval(breathingInterval); breathingInterval = null; } } catch {}
                try { document.getElementById('breathingAnimation').style.display = 'none'; } catch {}
                breathingStepCount = 0; // Reset breathing step counter
                talkBtn.disabled = false;
                stopBtn.disabled = true;
                statusEl.textContent = '';
            }

            async function stopCall() {
                inCall = false;
                endCallCleanup();
            }

            if (talkBtn) talkBtn.addEventListener('click', startConversation);
            if (stopBtn) stopBtn.addEventListener('click', stopCall);
        }
	</script>
</body>
</html>
